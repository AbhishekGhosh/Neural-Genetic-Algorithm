Pyneurgen: Python Neural Genetic Hybrids

Change Log
==========================================================================
Check http://pyneurgen.sourceforge.net for the latest documentation.

pyneurgen-0.3.1 Minor change made to the MANIFEST file that interfered with
                installation on Windows machines.

pyneurgen-0.3   Extensive testing has been implemented, although there is
                room for more. Unit testing is now somewhere over 90%.

                An attempt is made to formalize constants to clean up the
                code.

                Validation testing was added to neural nets.

                The demo programs were updated slightly.

                A bug when loading saved neural nets with recurrent features
                was fixed.

                Some bugs in grammatical evolution were fixed.
                Queuing/threading and garbage collection was removed.  Queing
                never worked very well, and it is not clear that garbage collection
                was much help either, so it is gone.

                In grammatical evolution, the completion process has been
                streamlined. In addition, there is a new feature for building
                families of solutions and using your custom built fitness
                landscape function to evaluate stopping.

                There was a bug in the cross-over function spotted by Franco in
                Argentina (blamaeda@gmail.com) whom I wish to thank.

                There were some bugs corrected in the fitness functions in the
                min and max functions in fitness lists.  Unit testing coverage
                is essentially 100% on fitness functions.  FitnessLinearRanking
                was streamlined for inputs.

                There is a first pass at logging, but unwieldy.

                With python 2.6, there is math.isnan, which replaces a
                homemade function.  Other utility functions were removed
                as useless abstractions.


pyneurgen-0.2   Updates primarily related to recurrent networks.

                In attempt to enable an easier use of recurrent features, a
                new set of classes has been implemented.

                NeuralNet.init_layers no longer takes copy_levels as a
                parameter. Rather, it accepts along with the number of nodes
                for input, hidden and output layers, classes derived from a
                class called RecurrentConfig, which modifies the network
                structure to embody recurrence. Using the feature, a class
                such as JordanRecurrent, ElmanSimpleRecurrent, or NARXRecurrent
                can be passed in and the appropriate structure configured.

                The RecurrentConfig class can easily be subclassed for other
                custom types.  As before, the copy nodes can be easily be added
                manually to network structures to achieve other kinds of
                structures.

                CopyNode now has some additional features to enable the above
                classes.  In the prior version, the Copy node value was always
                replaced by the source node value.  Now, a weighting system of
                existing_weight and incoming weight is used to modify the
                incoming values and/or retain part of the existing value.

                For flexibility, the copy node can take the source node's
                value, or activation, and have its activation type, independent
                of the source node's activation.

                Test modules are slightly more complete.

pyneurgen-0.1   Initial version

